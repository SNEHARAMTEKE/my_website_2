---
# categories:
# - tranquilpeak
# - showcase
date: "2022-09-14"
slug: Confidence Interval
thumbnailImage: images/ci.png
thumbnailImagePosition: left
title: Confidence Interval
---

Here you can find Confidence Interval analysis exercise in R

<!--more-->

```{r, setup, include=FALSE}
knitr::opts_chunk$set(
  message = FALSE, 
  warning = FALSE, 
  tidy=FALSE,     # display code as typed
  size="small")   # slightly smaller font for code
options(digits = 3)

# default figure size
knitr::opts_chunk$set(
  fig.width=6.75, 
  fig.height=6.75,
  fig.align = "center"
)
```

```{r load-libraries, include=FALSE}
library(tidyverse)  # Load ggplot2, dplyr, and all the other tidyverse packages
library(mosaic)
library(ggthemes)
library(lubridate)
library(here)
library(skimr)
library(janitor)
library(httr)
library(readxl)
library(vroom)
library(wbstats)
library(countrycode)
library(patchwork)
library(gganimate)
library(infer)
```

# Climate change and temperature anomalies

If we wanted to study climate change, we can find data on the *Combined
Land-Surface Air and Sea-Surface Water Temperature Anomalies* in the
Northern Hemisphere at [NASA's Goddard Institute for Space
Studies](https://data.giss.nasa.gov/gistemp). The [tabular data of
temperature anomalies can be found
here](https://data.giss.nasa.gov/gistemp/tabledata_v4/NH.Ts+dSST.txt)

To define temperature anomalies you need to have a reference, or base,
period which NASA clearly states that it is the period between
1951-1980.

Run the code below to load the file:

```{r weather_data, cache=TRUE}

weather <- 
  read_csv("https://data.giss.nasa.gov/gistemp/tabledata_v4/NH.Ts+dSST.csv", 
           skip = 1, 
           na = "***")

```

Notice that, when using this function, we added two options: `skip` and
`na`.

1.  The `skip=1` option is there as the real data table only starts in
    Row 2, so we need to skip one row.
2.  `na = "***"` option informs R how missing observations in the
    spreadsheet are coded. When looking at the spreadsheet, you can see
    that missing data is coded as "\*\*\*". It is best to specify this
    here, as otherwise some of the data is not recognized as numeric
    data.

Once the data is loaded, notice that there is a object titled `weather`
in the `Environment` panel. If you cannot see the panel (usually on the
top-right), go to `Tools` \> `Global Options` \> `Pane Layout` and tick
the checkbox next to `Environment`. Click on the `weather` object, and
the dataframe will pop up on a seperate tab. Inspect the dataframe.

For each month and year, the dataframe shows the deviation of
temperature from the normal (expected). Further the dataframe is in wide
format.

You have two objectives in this section:

1.  Select the year and the twelve month variables from the `weather`
    dataset. We do not need the others (J-D, D-N, DJF, etc.) for this
    assignment. Hint: use `select()` function.

2.  Convert the dataframe from wide to 'long' format. Hint: use
    `gather()` or `pivot_longer()` function. Name the new dataframe as
    `tidyweather`, name the variable containing the name of the month as
    `month`, and the temperature deviation values as `delta`.

```{r tidyweather}
tidyweather <- weather %>% 
               select(1:13) %>% 
               pivot_longer(!Year, names_to = "Month", values_to = "delta")
```

Inspect your dataframe. It should have three variables now, one each for

1.  year,
2.  month, and
3.  delta, or temperature deviation.

## Plotting Information

Let us plot the data using a time-series scatter plot, and add a
trendline. To do that, we first need to create a new variable called
`date` in order to ensure that the `delta` values are plot
chronologically.

> In the following chunk of code, I used the `eval=FALSE` argument,
> which does not run a chunk of code; I did so that you can knit the
> document before tidying the data and creating a new dataframe
> `tidyweather`. When you actually want to run this code and knit your
> document, you must delete `eval=FALSE`, **not just here but in all
> chunks were `eval=FALSE` appears.**

```{r scatter_plot}

tidyweather <- tidyweather %>%
  mutate(date = ymd(paste(as.character(Year), Month, "1")),
         month = month(date, label=TRUE),
         year = year(date))

ggplot(tidyweather, aes(x=date, y = delta))+
  geom_point()+
  geom_smooth(color="red") +
  theme_bw() +
  labs ( 
    x = "Date",
    y = "Temperature deviation",
    title = "Weather Anomalies",
  ) 

```

Is the effect of increasing temperature more pronounced in some months?
Use `facet_wrap()` to produce a seperate scatter plot for each month,
again with a smoothing line. Your chart should human-readable labels;
that is, each month should be labeled "Jan", "Feb", "Mar" (full or
abbreviated month names are fine), not `1`, `2`, `3`.

```{r facet_wrap, echo=FALSE}

ggplot(tidyweather, aes(x=date, y = delta))+
  geom_point()+
  geom_smooth(color="red") +
  facet_wrap(~month) +
  theme_bw() +
  labs (
    x = "Date",
    y = "Temperature deviation",
    title = "Weather Anomalies"
  )

```

It is sometimes useful to group data into different time periods to
study historical data. For example, we often refer to decades such as
1970s, 1980s, 1990s etc. to refer to a period of time. NASA calcuialtes
a temperature anomaly, as difference form the base periof of 1951-1980.
The code below creates a new data frame called `comparison` that groups
data in five time periods: 1881-1920, 1921-1950, 1951-1980, 1981-2010
and 2011-present.

We remove data before 1800 and before using `filter`. Then, we use the
`mutate` function to create a new variable `interval` which contains
information on which period each observation belongs to. We can assign
the different periods using `case_when()`.

```{r intervals}

comparison <- tidyweather %>% 
  filter(Year>= 1881) %>%     #remove years prior to 1881
  #create new variable 'interval', and assign values based on criteria below:
  mutate(interval = case_when(
    Year %in% c(1881:1920) ~ "1881-1920",
    Year %in% c(1921:1950) ~ "1921-1950",
    Year %in% c(1951:1980) ~ "1951-1980",
    Year %in% c(1981:2010) ~ "1981-2010",
    TRUE ~ "2011-present"
  ))

```

Inspect the `comparison` dataframe by clicking on it in the
`Environment` pane.

Now that we have the `interval` variable, we can create a density plot
to study the distribution of monthly deviations (`delta`), grouped by
the different time periods we are interested in. Set `fill` to
`interval` to group and colour the data by different time periods.

```{r density_plot, eval=FALSE}
library(viridis)
ggplot(comparison, aes(x = delta, fill = interval)) +
  geom_density(alpha=.6) +
 # theme(legend.position="none") +
  theme_bw()+
  scale_fill_viridis(discrete = TRUE, option = "D") +
  labs(x = "Delta",
       y = "Density",
       title = "Distribution of monthly deviations (`delta`) grouped by the different time periods")
  
```

So far, we have been working with monthly anomalies. However, we might
be interested in average annual anomalies. We can do this by using
`group_by()` and `summarise()`, followed by a scatter plot to display
the result.

```{r averaging}

#creating yearly averages
average_annual_anomaly <- tidyweather %>% 
  group_by(Year) %>%   #grouping data by Year
  
  # creating summaries for mean delta 
  # use `na.rm=TRUE` to eliminate NA (not available) values 
  summarise(mean_delta = mean(delta, na.rm = TRUE))

#plotting the data:
ggplot(average_annual_anomaly, aes(x = Year, y = mean_delta)) +
  geom_point() +
  #Fit the best fit line, using LOESS method
  geom_smooth(method = loess) +
  #change theme to theme_bw() to have white background + black frame around plot
  theme_bw() +
  labs(x = "Year", 
       y = "Mean tenperature deviation")


```

## Confidence Interval for `delta`

[NASA points out on their
website](https://earthobservatory.nasa.gov/world-of-change/decadaltemp.php)
that

> A one-degree global change is significant because it takes a vast
> amount of heat to warm all the oceans, atmosphere, and land by that
> much. In the past, a one- to two-degree drop was all it took to plunge
> the Earth into the Little Ice Age.

Your task is to construct a confidence interval for the average annual
delta since 2011, both using a formula and using a bootstrap simulation
with the `infer` package. Recall that the dataframe `comparison` has
already grouped temperature anomalies according to time intervals; we
are only interested in what is happening between 2011-present.

```{r, calculate_CI_using_formula}

comparison1 <- comparison %>% 
               summarise(delta = mean(delta, na.rm = TRUE))

#using formula
formula_ci <- comparison %>% 
              # filter by interval
              filter(interval == "2011-present") %>% 
              # calculate summary statistics for temperature deviation (delta) 
              summarize(mean_delta = mean(delta,na.rm=TRUE),
                        sd_delta = sd(delta,na.rm=TRUE),
                        count = n(),
                        t_critical = qt(0.975, count - 1),
                        se_delta = sd_delta/sqrt(count),
                        error_margin = t_critical*se_delta,
                        delta_low = mean_delta - error_margin,
                        delta_high = mean_delta + error_margin)

#print out formula_CI
formula_ci

set.seed(1234)
bootstrap_ci <- comparison %>% 
  filter(interval == '2011-present') %>% 
  specify(response = delta) %>%
  generate(reps = 1000, type = 'bootstrap') %>%
# Find the mean of each sample
  calculate(stat = 'mean') %>% 
  get_confidence_interval(level = 0.95, type = 'percentile')

bootstrap_ci

```

> The data shows that temperature deviation has increased over the years. The scatter plot of deviations shows cyclic behaviour. Looking at the monthly graphs, one cannot say that some months show more temperature deviation than others. The density plots show almost normal distributions of temperature deviation. Finally. the 95% confidence interval for deviation values is 1.02 to 1.11 approximately 


# Share of renewable energy production in the world

The National Bureau of Economic Research (NBER) has a a very interesting
dataset on the adoption of about 200 technologies in more than 150
countries since 1800. This is the[Cross-country Historical Adoption of
Technology (CHAT) dataset](https://www.nber.org/research/data/cross-country-historical-adoption-technology).

The following is a description of the variables

| **variable** | **class** | **description**                |
|--------------|-----------|--------------------------------|
| variable     | character | Variable name                  |
| label        | character | Label for variable             |
| iso3c        | character | Country code                   |
| year         | double    | Year                           |
| group        | character | Group (consumption/production) |
| category     | character | Category                       |
| value        | double    | Value (related to label)       |

```{r,load_technology_data}

technology <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-07-19/technology.csv')

#get all technologies
labels <- technology %>% 
  distinct(variable, label)

# Get country names using 'countrycode' package
technology <- technology %>% 
  filter(iso3c != "XCD") %>% 
  mutate(iso3c = recode(iso3c, "ROM" = "ROU"),
         country = countrycode(iso3c, origin = "iso3c", destination = "country.name"),
         country = case_when(
           iso3c == "ANT" ~ "Netherlands Antilles",
           iso3c == "CSK" ~ "Czechoslovakia",
           iso3c == "XKX" ~ "Kosovo",
           TRUE           ~ country))

#make smaller dataframe on energy
energy <- technology %>% 
  filter(category == "Energy")

# download CO2 per capita from World Bank using {wbstats} package
# https://data.worldbank.org/indicator/EN.ATM.CO2E.PC

co2_percap <- wb_data(country = "countries_only", 
                      indicator = "EN.ATM.CO2E.PC", 
                      start_date = 1970, 
                      end_date = 2022,
                      return_wide=FALSE) %>% 
  filter(!is.na(value)) %>% 
  #drop unwanted variables
  rename(year = date) %>% 
  select(-c(unit, obs_status, footnote, last_updated)) 
  

# get a list of countries and their characteristics
# we just want to get the region a country is in and its income level
countries <-  wb_cachelist$countries %>% 
  select(iso3c,region,income_level)

```

This is a very rich data set, not just for energy and CO2 data, but for many other technologies. In our case, we just need to produce a couple of graphs-- at this stage, the emphasis is on data manipulation, rather than making the graphs gorgeous.

First, produce a graph with the countries with the highest and lowest % contribution of renewables in energy production. This is made up of `elec_hydro`, `elec_solar`, `elec_wind`, and `elec_renew_other`. You may want to use the *patchwork* package to assemble the two charts next to each other.
 
```{r min-max_renewables, out.width="100%"}
energy_select <- c('elec_hydro', 'elec_solar', 'elec_wind', 'elec_renew_other')

energy_analysis1 <- energy %>% 
                   filter(variable %in% energy_select, year == 2019) %>% 
                   group_by(country) %>% 
                   summarise(
                     total_renewable_energy = sum(value, na.rm = TRUE)
                   ) 

energy_analysis2 <- energy %>% 
                   filter(variable == 'elecprod', year == 2019) %>% 
                   group_by(country) %>% 
                   summarise(total_energy = sum(value, na.rm = TRUE)) 

energy_analysis <- left_join(energy_analysis1, energy_analysis2, by = "country") %>% 
                   mutate(percent_contribution = total_renewable_energy/total_energy) %>% 
                   select(country, percent_contribution) %>% 
                   filter(percent_contribution != 0, !is.na(percent_contribution) )

energy_analysis_top20 <- energy_analysis %>% 
                         slice_max(order_by = percent_contribution, n = 20) %>% 
                         mutate(primary_country = fct_reorder(country, percent_contribution)) %>%
                         ggplot(mapping = aes(x = percent_contribution, y = primary_country)) +
                         geom_col() +
                         scale_x_continuous(labels = scales::percent_format()) + 
                         theme(axis.title.x = element_blank(), 
                               axis.title.y = element_blank()) 

energy_analysis_bottom20 <- energy_analysis %>% 
                         slice_min(order_by = percent_contribution, n = 20) %>% 
                         mutate(primary_country = fct_reorder(country, percent_contribution)) %>%
                         ggplot(mapping = aes(x = percent_contribution, y = primary_country)) + 
                         geom_col() +
                         scale_x_continuous(labels = scales::percent_format()) + 
                         theme(axis.title.x = element_blank(), 
                               axis.title.y = element_blank()) 

energy_analysis_top20 + energy_analysis_bottom20 +
  plot_annotation(title = "Highest and lowest % of renewables in energy production",
                  subtitle = "2019 data")

                   
```

Second, you can produce an animation to explore the relationship between CO2 per capita emissions and the deployment of renewables. As the % of energy generated by renewables goes up, do CO2 per capita emissions seem to go down?


```{r my_animation, out.width="100%"}
energy_select <- c('elec_hydro', 'elec_solar', 'elec_wind', 'elec_renew_other')
energy_analysis3 <- energy %>% 
                   filter(variable %in% energy_select) %>% 
                   group_by(country, year) %>% 
                   summarise(total_renewable_energy = sum(value, na.rm = TRUE)) 

energy_analysis4 <- energy %>% 
                   filter(variable == 'elecprod') %>% 
                   group_by(country, year) %>% 
                   summarise(total_energy = sum(value, na.rm = TRUE)) 

energy_analysis5 <- left_join(energy_analysis3, energy_analysis4, by = c("country", "year")) %>% 
                   mutate(percent_contribution = total_renewable_energy/total_energy) %>% 
                   select(country, year, percent_contribution) %>% 
                   filter(percent_contribution != 0, !is.na(percent_contribution) )

joined_energy <- left_join(energy_analysis5, co2_percap, on = c(country, year))
joined_energy2 <- left_join(joined_energy, countries, on = iso3c) %>% 
                  drop_na() %>% 
                  mutate(year = as.integer(year))

ggplot(data = joined_energy2, aes(x = percent_contribution, y = value, colour = income_level)) +
  geom_point() +
  facet_wrap(~income_level) +
  scale_x_continuous(labels = scales::percent_format(accuracy = 1)) +
  labs(title = 'Year: {frame_time}', 
       x = '% renewables', 
       y = 'CO2 per cap') +
  transition_time(year) +
  ease_aes('linear') +
  theme_bw() +
  theme(legend.position="none")
```



